---
title: "Project PTDS"
author: "Luca Bron, David Germano, Patrik Grandadam, Vincent Lomazzi, Edgar Raisin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: cerulean
    highlight: tango
---

```{r message = FALSE, warning = FALSE, echo = FALSE}
library(robotstxt)
library(xml2)
library(rvest)
library(magrittr)
library(stringr)
library(dplyr)
library(plotly)
library(ggmap)
library(googleway)
library(kableExtra)
library(leaflet)
library(caret)
library(googleway)
# devtools::install_github("vincentlomazzi/swissimmo")
library(swissimmo)
```

# Introduction

## Objectives 

... what we want to achieve...

## Methodology

... How we achieve it... 

# Modelling

## Legal check

Before beginning anything, we have to make sure that we are respecting the utilization conditions of Immoscout24.  
Therefore, we look if the path to which we will web scrap the data is allowed by the website.

```{r}
paths_allowed(paths = "/en/real-estate/rent/city/",
              domain = "https://www.immoscout24.ch")

# get_robotstxt(domain = "https://www.immoscout24.ch")
```

We see that the path is allowed and not restricted in the robots.txt of the website. We can begin our analysis.

## Web scrapping 

The first step of our process is to web scrap the data from Immoscout24.  

In order to perform our analysis, we first would like to have all relevant informations concerning the housings for different cities of interest.  

Thus, for given cities, we would like to retrieve all housings that are currently published for renting and their respective number of rooms, square meters, price and address. 

Thanks to the function *get_immodata* from the *swissimmo* package that we created and that is available publicly on github, we can retrieve all these informations. 

This function takes as an argument a vector containing the names of the cities for which the user would like to web scrap the data and returns a tidy dataframe with all relevant informations.  
More information are available using the help of the function.

As an example, we propose you to run the following to have the data related to Bussigny and Nyon.

```{r}
cities <- get_immodata(c("bussigny", "nyon"))
```

The data is collected in a dataframe. Each row is an observation and the columns contain the relevant informations. Below the first rows of the created dataframe.

```{r}
head(cities)
```

Having a clean dataframe is great. A lot of descriptive analysis could already be performed.  
However, it could be interesting to have a model predicting the price of the housings and to compare them to their actual renting price. This could enable to see if a flat is overpriced or underprice. 

## Predicting "Market Prices"

Thanks to the *predict_price* function of the same *swissimmo* package, it is possible to forecast the prices of the different housings based on their characteristics.  

This function allows to either use as input the number of rooms, square meters and city of a housing in  which the user might be interested or a dataframe that contains this different columns (typically, a dataframe that has been obtrained thaks to the *get_immodata()* function.  

The function returns the estimated prices of the single housing when rooms, m2 and city are given, or the inputted dataframe to which a new column for the estimated price has been added.  

The user can also specify the model that should be used. This model should be supported as a regression model by the *"caret"* package (see [available models](http://topepo.github.io/caret/available-models.html) ).
After having tested different models and used a cross-validation procedure to assess their performance, we would advise the users to use the random forest ("rf") that offers the lowest RMSE. However, this model could be innappropriate in some cases and it the user might use his intuition to find a more appropriate one.  
Note that, as the main goal of this report is not to present forecasting methods, the model used are not tuned and using the defaut parameters from the *caret* package. 

First, we can retrieve the estimated price for an appartment of 59 m2 and 3 rooms located in Nyon.

```{r, note = FALSE}
predict_price(rooms = 3, m2 = 59, city = "nyon")
```

The estimated price and a message telling us that this price has been computed for a single housing and not for a dataframe are prompted.  
Otherwise, if we analyse a whole city and not a single housing, it is possible to directly use as an input a dataframe.  

As an example, we can use this function using as an input the object *cities* that we created before.  

```{r}
predictions <- predict_price(cities)
```

*Note*: warnings or errors might be displayed if the user uses too much or too few parameters...

Rather than having only the predicted prices as output, this new object *prediction* uses the S3 methodology. The class *pred* has been assigned to this object.  
We can directly retrieve the original dataframe to which a column *predicted_price* has been added thanks to the *summary* function (see *summary.pred* for help as the S3 methodology is used) of this object.  

Below, the result of the *summary* function for the previously created *predictions* object. 

```{r, echo = FALSE}
summary(predictions) %>% 
  kable(caption = "10 first rows of the output of the summary function") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = T) %>%
  scroll_box(width = "65%", height = "250px")
  
```

The new dataframe contains all relevant informations, including the estimated market price to which it should be sold and will be used later for a shiny app illustration based on the Swiss map. 

For the moment, one could be interesting to retrieve a graph showing the actual prices against the predicted prices of the different housings to be able to see which one are over/under estimated.  

To do this, we can again use our *predictions* object that we created before, and plot it with the *plot* function (*?plot.pred* to see the help).  
In this graph, the values below the lines are the one with estimated values higher than the actual values. These housing are underestimated.  
In order to be able to retrieve these points of interest, the function incorporates a ShinyApp..  
It is possible to click on the different points or to brush many at the same time to retrieve their informations. The pop-up window gives main informations about the good (price, estimed price, adress, etc).
This function has to be runned directly in the console to work efficiently as it uses a ShinyApp.

```{r, eval = FALSE}
plot(predictions) # to be ran in the console
```

The next step of our process will be to use the different data that we recorded till here and to plot each housing with their different characteristics on an interactive map of Switzerland. To do this, we would need the geographical coordinates (longitude and latitude) of each housing.  

The tool that we decide to use is using *GoogleMaps* and retrieves these coordinates based on the address that are inputted. 
However, this feature requires an API key provided by *Google* is not free of charged passed a certain limit. Moreover, this feature requires quite some time to be ran.  

For more convenience, we provide you a dataframe which is the result of the function *get_immodata2* that can be used after having received the adequate key (if you have interest in running this function, use the function *set_key()* with the provided key. 
This function is an amelioration of our first *get_immodata* function and directly provides all the information web scrapped, the longitude, the latitude and the predicted price.  

The following dataframe is the result of this function used on the 8 biggest cities of Switzerland. 


```{r}
# result from get_immodata2(...) %>% predict_price() %>% summary()
all_cities <- readRDS(file = "all_cities.rds") 
```

# Shiny App




# Annexes

```{r}
# After having tested multiple models with the caret package, we observe that
# the random forest with ntree = 500 and mtry = 3 leads to the best results 
# in term of minimizing the RMSE. We decide to use this model to forecast
# the price of the different housings. 
# The explanatory variables used are the rooms, m2 and the city. We didn't use
# the postcode as too many factors would have been used.

# train_control <- trainControl(method = "cv", number = 10)

# rf_cv <- train(form = price ~ rooms + m2 + city,
#                  data = all_cities,
#                  trControl = train_control,
#                  tuneGrid = data.frame(
#                    mtry = c(2:7)), # can take a while
#                  method = "rf")
# rf_cv$results
# 
# svm_cv <- train(form = price ~ rooms + m2 + city,
#                  data = all_cities,
#                  trControl = train_control,
#                  tuneGrid = data.frame(
#                    C = c(0.1, 1, 10, 100)),
#                  method = "svmRadialCost")
# svm_cv$results
# 
# 
# mars_cv <- train(form = price ~ rooms + m2 + city,
#                  data = all_cities,
#                  trControl = train_control,
#   method = "bagEarthGCV")
# mars_cv$results
# 
# gam_cv <- train(form = price ~ rooms + m2 + city,
#                  data = all_cities,
#                  trControl = train_control,
#   method = "gam")
# gam_cv$results

set.seed(1)
index.train <- createDataPartition(y = all_cities$price, p = 0.7, list = FALSE)
train_set <- all_cities[index.train,]
test_set <- all_cities[-index.train,]

rf_price <- randomForest::randomForest(price ~ rooms + m2 + city,
                                       data = train_set,
                                       ntree = 500,
                                       mtry = 3)

# The predicted values on the testing set
predictions <- predict(rf_price, newdata = test_set)

# RMSE
(predict(rf_price, newdata = test_set) - test_set$price) ^ 2 %>% mean %>% sqrt

# The plot of the real values against the predictions
ggplot() + 
  geom_point(aes(x = predict(rf_price, newdata = test_set), y = test_set$price)) +
  my_theme() +
  geom_abline(slope = 1, intercept = 1, color = "red") +
  xlab("Predicted values of the testing set") +
  ylab("Real value of the testing set") 
```
Now, we now that the random forest is the model to choose and we can build a new one on the whole dataset. Of course, we have overfitting as we predict instances that we already know.



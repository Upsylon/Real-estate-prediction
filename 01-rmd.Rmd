---
title: "Project PTDS"
author: "Luca Bron, David Germano, Patrik Grandadam, Vincent Lomazzi, Edgar Raisin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: cerulean
    highlight: tango
---

```{r}
library(robotstxt)
library(xml2)
library(rvest)
library(magrittr)
```


# Webscrapping

Example data structure de Iegor a rearranger

```{r}
cities <- list(
  zurich = list(),
  geneve = list(),
  basel = list(),
  lausanne = list(),
  bern = list(),
  winterthur = list(),
  lucerne = list(),
  lugano = list()
  )

prices <- cities
rooms_m2 <- cities


# list(
#   zurich = list(page1 = c(12, 12, 1213),
#     page2 = c(1222, 12, 1213)),
#   geneva = list()
# )
    

# # lausanne
# page1 <- c(12, 13, 14)
# attr(x = page1, which = "url") <- "http..."
# 
# 
# page2 <- c(11, 13, 14)
# attr(x = prices$zurich$page2, which = "url") <- "http...2"
# 
# prices <- list(
#   lausanne = list(page1, page2),
#   basel = list(page1, page2)
# )
# 
# prices
```


Cities of interest.

```{r}
# cities2 <- c("Zurich", "Geneve", "Basel", "Lausanne", "Bern",
#             "Winterthur", "Lucerne", "Lugano")
```


## Immoscout

Is the path allowed for each city? 

```{r, eval = FALSE}
paths_allowed(paste(paths="/en/real-estate/rent/city/", prices, sep=""),
              domain="https://www.immoscout24.ch")
get_robotstxt(domain="https://www.immoscout24.ch")
```
--> Yes 


LOOPING OVER EACH CITY

Getting the URL of each cities in new variables linked to each of them:

```{r}
# for (i in 1:length(cities2)){
# assign(paste("url_immoscout_", cities2[i], sep=""), paste("https://www.immoscout24.ch/en/real-estate/rent/city-", cities2[i], sep=""))
#   }
```

```{r}
for (i in 1:length(cities)){
  attr(cities[[i]], which="url") <- paste("https://www.immoscout24.ch/en/real-estate/rent/city-", names(cities[i]), sep="") 
}
for (i in 1:length(prices)){
  attr(prices[[i]], which="url") <- paste("https://www.immoscout24.ch/en/real-estate/rent/city-", names(prices[i]), sep="") 
}
for (i in 1:length(rooms_m2)){
  attr(rooms_m2[[i]], which="url") <- paste("https://www.immoscout24.ch/en/real-estate/rent/city-", names(rooms_m2[i]), sep="") 
}

```



```{r}
pages <- list()
for( i in 1:length(prices)){
  pages[[i]] <- read_html(x = paste0(unlist(attributes(prices[[i]]),use.names=FALSE))) %>%
  html_nodes(css = ".cXTlXt") %>%
  html_text() %>%
  as.numeric() %>%
  max(na.rm = TRUE) %>%
  subtract(e2 = 1) %>%
  seq(from = 1) 
}
```

Looping over cities and pages to get all prices for all cities
```{r}
# for (i in 1:length(cities2)){
#   for (page in paste("pages_immoscout_", cities2[i], sep="") %>% get){
#     url_path_page_immoscout <-
#       paste("https://www.immoscout24.ch/en/real-estate/rent/city-",
#       cities2[i], sep="") %>% 
#     paste("?pn=", page, sep="")
# 
# ## doesnt work...
# assign(paste("prices_immoscout_", cities2[i], sep="") %>% paste("_page_", page, sep=""), read_html(url_path_page_immoscout) %>% 
#   html_nodes(".fFoWRd") %>%
#   html_text())
#   }
# }
```

Getting the prices with the "Selector Gadget":

```{r}
# .fFoWRd --> the prices
# .kEhyoM .ehLwuE --> the nb of rooms and the surface
# .gDVamO .fUZwLT --> the address
# .gDVamO .fUZwLT , .kEhyoM .ehLwuE, .fFoWRd --> all combined without other perturbating lements
```

Getting the prices
```{r, eval=FALSE}
for (i in 1:length(prices)){
  for (page in pages[[i]]){  
    url_path_page_immoscout <- prices[[i]] %>% 
      attributes %>% 
      unlist(use.names=FALSE) %>% 
      paste0 %>%
      paste("?pn=", page, sep="") 
      
    prices[[i]][[page]] <- list()
     prices[[i]][[page]] <- read_html(url_path_page_immoscout) %>% 
      html_nodes(".fFoWRd") %>%
      html_text() %>% 
       cbind %>% 
       as.vector %>% 
       gsub(".\u2014","",.) %>% # substracting disturbing elements
       gsub("CHF ","",.) %>% 
       gsub(",","",.) %>% 
       as.numeric
  }
}
unlisted_price <- unlist(prices) %>% data.frame
zurich <- unlisted_price[grep('^zurich', rownames(unlisted_price)),] %>% data.frame
```

Getting the number of rooms and size of the apartment/house: 
```{r, eval=FALSE}
for (i in 1:length(rooms_m2)){
  for (page in pages[[i]]){  
    url_path_page_immoscout <- rooms_m2[[i]] %>% 
      attributes %>% 
      unlist(use.names = FALSE) %>% 
      paste0 %>%
      paste("?pn=", page, sep="") 
      
    rooms_m2[[i]][[page]] <- list()
     rooms_m2[[i]][[page]] <- read_html(url_path_page_immoscout) %>% 
      html_nodes(".kEhyoM .ehLwuE") %>%
      html_text() %>% 
      cbind %>%
      gsub("\u00B2","",.) %>%
      strsplit(",")
  }
}
```

everything:
```{r}
for (i in 1:length(cities)){
  for (page in pages[[i]]){  
    url_path_page_immoscout <- cities[[i]] %>% 
      attributes %>% 
      unlist(use.names = FALSE) %>% 
      paste0 %>%
      paste("?pn=", page, sep="") 
      
    cities[[i]][[page]] <- list()
     cities[[i]][[page]] <- read_html(url_path_page_immoscout) %>% 
      html_nodes(".gDVamO .fUZwLT , .kEhyoM .ehLwuE, .fFoWRd") %>%
      html_text() 
  }
}
a <- read_html(url_path_page_immoscout) %>% 
      html_nodes(".gDVamO .fUZwLT , .kEhyoM .ehLwuE, .fFoWRd") %>%
      html_text() %>% 
      gsub("\u00B2","",.) %>% 
       gsub(".\u2014","",.) %>% data.frame


unlisted_cities <- unlist(cities) %>% data.frame
zurich <- unlisted_cities[grep('^zurich', rownames(unlisted_cities)),] %>% data.frame
```



```{r}
write.csv(zurich, file = "zurich.csv")
```




getting the elements of interest (price, title) for each city (only the 1st page)
```{r}
# for (i in 1:length(prices)){
# assign(paste("characs_", prices[i], sep=""), paste("url_immoscout_", prices[i], sep="")  %>% get %>%
#     html_nodes(".gDVamO .fUZwLT , .kEhyoM .ehLwuE, .fFoWRd") %>%
#     html_text())
# }
```
